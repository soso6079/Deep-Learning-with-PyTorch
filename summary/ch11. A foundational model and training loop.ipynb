{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ch11. A foundational model and training loop\n",
    "---\n",
    "> - `DataLoader`로 데이터 로딩하기\n",
    "> - CT 데이터 분류기 구현\n",
    "> - 어플리케이션 기본 구조 설정\n",
    "> - metric 로깅\n",
    "\n",
    "#### 이 노트북은 코드 실행이 되지 않는다. 책에서 설명하는 부분들을 정리하기 위해 작성한 노트북이다.\n",
    "\n",
    "이번 장에서는 분류 모델을 만드는 것과 훈련 루프를 만들어본다. 기존에 설명했던 전체 프로젝트에서는 아래 그림에 해당하는 부분이다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190555112-8e0215b5-b1e0-4ce5-a6e5-dd4f7c94b234.png)\n",
    "\n",
    "이번 장에서 구현할 사항을 자세하게 나타내면 아래 그림과 같다. 전체 구조는 다음과 같다.\n",
    "\n",
    "- 데이터를 불러오고 모델을 초기화한다.\n",
    "- epoch 별로 어느 정도 임의로 훈련한다.\n",
    "    - `LunaDataset`에서 반환된 배치를 루프한다.\n",
    "    - data-loader가 적합한 배치를 불러온다.\n",
    "    - 배치를 분류 모델로 전달한다.\n",
    "    - loss를 계산한다.\n",
    "    - metric을 기록한다.\n",
    "    - 가중치를 업데이트한다.\n",
    "    - valid 배치를 루프한다.\n",
    "    - 적합한 vliad 배치를 불러온다.\n",
    "    - loss를 계산한다.\n",
    "    - 결과를 기록한다.\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190555189-eb7543ea-fee2-40f5-975f-cbfff9fd9a83.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "지금부터 만들 training loop는 기존에 우리가 만들었던 training loop과 크게 두 가지 차이점이 있다.\n",
    "1. 좀 더 정교하게 만든다.\n",
    "   - 너무 단순하면 성능이 떨어지거나, 유지보수가 힘들어지거나, 뭘 하는지 설명하기 어려워진다.\n",
    "2. train이 진행되는 동안 다양한 metric을 기록한다.\n",
    "   - 프로젝트에 적합한 metric을 알 수 있다.\n",
    "\n",
    "전체 프로젝트 입장에서 봤을 때도 구조적인 차이가 있는데, 바로 완전한 command-line 어플리케이션이라는 점이다. 즉 주피터나 쉘에서도 동작할 수 있게끔 설계한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import argparse\n",
    "# code/p2_run_everything.ipynb\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import torch.cuda\n",
    "\n",
    "from util.util import importstr\n",
    "from util.logconf import logging\n",
    "log = logging.getLogger('nb')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9312\\2334740401.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDense\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mFlatten\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSequential\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9312\\3248824933.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfashion_mnist\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfashion_mnist\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfashion_mnist\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mx_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx_train\u001B[0m \u001B[1;33m/\u001B[0m \u001B[1;36m255.0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# code/p2_run_everything.ipynb\n",
    "# 코랩으로 실행해야 함\n",
    "def run(app, *argv):\n",
    "    argv = list(argv)\n",
    "    argv.insert(0, '--num-workers=4')\n",
    "    log.info(\"Running: {} ({!r}).main()\", format(app, argv))\n",
    "\n",
    "    app_cls = importstr(*app.rsplit('.', 1))\n",
    "    app_cls(argv).main()\n",
    "\n",
    "    log.info(\"Finished: {}.{!r}).main()\".format(app, argv))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "format() argument 2 must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\516993419.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# code/p2_run_everything.ipynb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'p2ch11.training.LunaTrainingApp'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'--epochs=1'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\4228175718.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(app, *argv)\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0margv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0margv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minsert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'--num-workers=4'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mlog\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Running: {} ({!r}).main()\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mapp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mapp_cls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mapp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrsplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'.'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: format() argument 2 must be str, not list"
     ]
    }
   ],
   "source": [
    "# code/p2_run_everything.ipynb\n",
    "run('p2ch11.training.LunaTrainingApp', '--epochs=1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "아래 코드는 로깅을 위해 일반적으로 쓰이는 코드다. 다른 프로젝트를 위해 재사용할 수도 있다. 특히 `__init__`을 파싱하는 부분은 어플리케이션을 따로 configure할 수 있게 해준다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:31, class LunaTrainingApp\n",
    "class LunaTraingApp:\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:        # caller가 arg가 없다면 command-line에서 arg를 얻는다.\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--num-workers',\n",
    "                            help='Number of worker processes for background data loading',\n",
    "                            default=8,\n",
    "                            type=int,\n",
    "                            )\n",
    "        #...line 63\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "        self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H. %M. %S') # timestamp\n",
    "    def main(self):\n",
    "        log.info(\"starting {}, {}\". format(type(self).__name__, self.cli_args))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "epcoh를 실행하기 전에 두가지 할일이 있다. 먼저 모델과 optimizer를 초기화해야 하는 것과 `Dataset`과 `DataLoader`를 초기화 해야 한다.\n",
    "`LunaDataSet`은 epoch 마다 무작위 샘플을 정의하고 `DataLoader`는 데이터를 불러오고 프로젝트의 어플리케이션에 데이터를 제공한다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190560426-182cfb99-8712-407c-9202-f1c1672e65d4.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "이 챕터에서는 `LunaModel`을 블랙박스로 생각하고 시작해보자."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:31, class LunaTrainingApp\n",
    "class LunaTraingApp:\n",
    "    def __init__(self, sys_argv=None):\n",
    "        #...line 70\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "\n",
    "        self.model = self.initModel()\n",
    "        self.optimizer = self.initOptimizer()\n",
    "\n",
    "    def initModel(self):\n",
    "        model = LunaModel()\n",
    "        if self.use_cuda:\n",
    "            log.info(\"Using CUDA; {} devices.\".foramt(torch.cuda.device_count()))\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                model = nn.DataParall(model)\n",
    "            model = model.to(self.device)\n",
    "        return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드 16 번째 줄에 사용한 `DataParall`가 GPU를 병렬로 사용하기 제일 좋은 선택지는 아니다.\n",
    "\n",
    "> `DataParall` vs `DistributedDataParall`\n",
    ">  - `DataParall`: 간단하게 모델을 래핑해서 multiple GPU를 활용한다. 하지만 제한된 자원만 사용한다.\n",
    ">  - `DistributedDataParall`: 하나 이상의 GPU나 machine을 사용하고 싶을 때 추천하는 래핑 클래스다. 하지만 설정이 복잡하기 때문에 여기서는 사용하지 않는다. 도큐먼트를 참조하자 https://pytorch.org/tutorials/intermediate/ddp_tutorial.html\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "optimizer를 만들기 전에 모델을 GPU로 옮겨야 한다. 그렇지 않으면 옵티마이저는 CPU에서 파라미터 값을 찾으려 한다.\n",
    "\n",
    "이 프로젝트에서는 optimizer로 SGD를 사용한다. SGD와 모멘텀을 사용한다. learning rate을 SGD는 0.001, 모멘텀은 0.9로 하면 안전한 선택이다. 다양한 learning rate 값을 사용해보고 네트워크 사이즈 등을 조정하는걸 `hyperparameter search`라고 한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터를 불러올 때는 모델이 요구하는 데이터 형식으로 맞춰줘야 한다. 예를 들어 `torch.nn.Conv3d`는 (N, C, D, H, W): Number of sample, Channels per sample, Depth, Height, Wdith의 형태로 데이터를 넣어야 한다. 이를 맞추기 위해 `LunaDataset.__getitem__`에서 `ct_t.unsqueeze(0)`을 통해 차원을 맞춰줬다.\n",
    "\n",
    "또 훈련을 진행할 때는 여러 개의 샘플(배치)을 동시에 처리해 병렬 연산을 진행한다. 이 부분은 파이토치의 `DataLoader`를 통해서 구현할 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:89, LunaTrainingApp.initTrainDl\n",
    "def initTrainDl(self):\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "    )\n",
    "\n",
    "    batch_size = self.cli_args.batch_size\n",
    "    if self.use_cuda:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=self.cli_args.num_workers,\n",
    "        pin_memory=self.use_cuda, # 고정된 메모리 영역이 GPU로 빠르게 보내진다.\n",
    "        )\n",
    "    return train_dl\n",
    "\n",
    "def main(self):\n",
    "    log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "    train_dl = self.initTrainDl()\n",
    "    val_dl = self.initValDl()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`DataLoader`는 각 샘플을 배칭할 수 있을 뿐 아니라, 데이터를 병렬로 불러올 수 있다. 또한 GPU 계산과 데이터 로딩을 동시에 진행시켜 주기 땜누에 프로젝트를 빠르게 실행할 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 첫 번째 경로 신경망 설계\n",
    "---\n",
    "8장에서 만들었던 신경망 설계를 기본으로 한다.\n",
    "\n",
    "분류 모델에서는 tail, backbone, head로 구성된 구조가 흔하다. tail은 입력을 신경망에 넣기 전에 전처리 과정을 담당하는 부분이다. backbone에서 원하는 형태로 입력을 만들어야 하기 때문에 다른 부분과는 형태가 다른 경우가 많다. 본 프로젝트에서는 단순 배치 정규화 계층을 사용한다.\n",
    "\n",
    "다음으로 backbone은 여러 계층을 가지는데 일반적으로는 연속된 블럭이 배치된다. 각 블럭은 동일한 셋의 계층을 가지며, 블럭을 거칠 때마다 필요한 입력 크기나 필터 수가 달라진다. 본 프로젝트에서는 두 개의 3x3 컨볼루션과 reLu 활성화 함수를 사용하고 마지막에는 맥스 풀링 연산을 사용한다. 아래 그림의 오른쪽 부분이 이에 해당한다.\n",
    "\n",
    "블럭을 코드로 구현하면 아래와 같다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190589244-8ef7b79e-c466-4f8c-af82-b8b27c2cd565.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # model.py:67, class LunaBlock\n",
    "\n",
    "class LunaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, conv_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n",
    "        )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(\n",
    "            conv_channels, conv_channels, kernel_size=3, padding=1, bias=True,\n",
    "        )\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.maxpool = nn.MaxPool3d(2, 2)\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        block_out = self.conv1(input_batch)\n",
    "        block_out = self.relu1(block_out)\n",
    "        block_out = self.conv2(block_out)\n",
    "        block_out = self.relu2(block_out)\n",
    "\n",
    "        return self.maxpool(block_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "신경망의 head 부분에서는 backbone의 출력을 받아 원하는 출력 형태로 바꾼다. 컨볼루션 신경망에서는 평탄화(flattening)하고 완전 연결 계층(fully connected layer)하는 역할을 하기도 한다. 이미지가 객체가 많은 형태거나 구별할 대상이 많다면 완전 연결 계층을 사용하는게 적합하다. 하지만 이 프로젝트에서는 두 가지로 분류하기 때문에 복잡하게 만들 필요 없이 하나의 평탄화 계층만 사용한다.\n",
    "\n",
    "또한 시작할 때는 이런 식으로 단순하게 만들고 이유가 명확할 때 복잡성을 추가하는 것이 좋다.\n",
    "\n",
    "아래 그림에서 우리가 사용하는 컨볼루션을 살펴볼 수 있다. 실제로 적용되는 블럭에서는 3x3x3 컨볼루션을 사용한다. 컨볼루션층이 쌓여있기 때문에 마지막 출력 복셀은 컨볼루션 커널의 크기보다 입력에 영향을 받는다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190594445-d80b2364-9fb3-45ee-abf6-fae10fa2aee0.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "전체 모델 구현은 아래 코드와 같다. 먼저 tail에서는 `nn.BatchNorm3d`를 이용해서 정규화(평균값 0, 표준편차 1)를 한다.\n",
    "\n",
    "backbone에서는 네 개의 블럭을 반복한다. 각 블럭은 2x2x2 맥스 풀링으로 끝나기 때문에 네 개의 층을 거치면 이미지는 각 차원 별로 16배가 줄어든 형태가 된다. backbone을 거치고 나면 데이터는 2x3x3이 된다.\n",
    "\n",
    "마지막으로 tail에서는 `nn.Softmax`로 마무리된다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LunaModel(nn.Module):\n",
    "    def __init__(self, in_channels=1, conv_channels=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tail_batchnorm = nn.BatchNorm3d(1) # tail\n",
    "\n",
    "        self.block1 = LunaBlock(in_channels, conv_channels)# backbone\n",
    "        self.block2 = LunaBlock(conv_channels, conv_channels * 2)\n",
    "        self.block3 = LunaBlock(conv_channels * 2, conv_channels * 4)\n",
    "        self.block4 = LunaBlock(conv_channels * 4, conv_channels * 8)\n",
    "\n",
    "        self.head_linear = nn.Linear(1152, 2) #head\n",
    "        self.head_softmax = nn.Softmax(dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 컨볼루션을 선형으로 변환하기\n",
    "위처럼 모델을 정의하고 계속 진행하면 문제가 발생한다. `self.block4`의 출력을 완전 연결 계층에 넣을 수 없기 때문이다. 출력은 샘플마다 2x3x3 이미지에 64개 채널을 갖는데, 완전 연결 계층은 1차원 벡터를 받을 수 있기 때문이다. `forward` 메소드를 살펴보자.\n",
    "\n",
    "아래 코드에서 완전 연결 계층에 전달하기 전에 `view`를 이용해 flatten을 해야한다. `forward` 메소드는 출력을 위해 logit과 softmax로 확률을 만든다. 훈련 중에는 `nn.CrossEntropyLoss` 계산을 위해 logit 값을 사용하고 실제로 분류할 때는 확률 값을 사용한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  model.py:50, LunaModel.forward\n",
    "\n",
    "def forward(self, input_batch):\n",
    "    bn_output = self.tail_batchnorm(input_batch)\n",
    "\n",
    "    block_out = self.block1(bn_output)\n",
    "    block_out = self.block2(block_out)\n",
    "    block_out = self.block3(block_out)\n",
    "    block_out = self.block4(block_out)\n",
    "\n",
    "    conv_flat = block_out.view(\n",
    "        block_out.size(0), # 배치 크기\n",
    "        -1,\n",
    "    )\n",
    "    linear_output = self.head_linear(conv_flat)\n",
    "\n",
    "    return linear_output, self.head_softmax(linear_output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 초기화\n",
    "모델이 좋은 성능을 내려면 가중치, 편향값 등 여러 파라미터에 대해 주의할 점이 있다.\n",
    "\n",
    "모든 가중치가 1보다 커지는 경우를 생각해보자. (residual connection이 없는 경우) 이 가중치 값으로 연산을 반복하면 출력 값이 매우 커지게 된다. 또, 모든 가중치가 1보다 작다면 출력 값을 사라지게 만든다. 역전파에서의 기울기도 동일한 문제가 발생한다.\n",
    "\n",
    "이를 해결하는 방법은 신경망 가중치를 초기화하는 것이다. 이를 파이토치에서 제공하진 않으므로 우리가 직접 초기화해야 한다. `_init_weights`를 살펴보자. 코드를 자세하게 이해할 필요는 없고 이 메소드를 이용해 진행한다는 것만 기억하자.\n",
    "\n",
    "Kaiming(he) initialization: https://brunch.co.kr/@kmbmjn95/37"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.py:30, LunaModel._init_weights\n",
    "\n",
    "def _init_weights(self):\n",
    "    for m in self.modules():\n",
    "        if type(m) in {\n",
    "            nn.Linear,\n",
    "            nn.Conv3d,\n",
    "            nn.Conv2d,\n",
    "            nn.ConvTranspose2d,\n",
    "            nn.ConvTranspose3d,\n",
    "        }:# kaiming(he) initialization은 relu 연산을 위해 만들어진 초기화 방법이다.\n",
    "            nn.init.kaiming_normal_(\n",
    "                m.weight.data, a=0, mode='fan_out', nonlinearity='relu',\n",
    "            )\n",
    "            if m.bias is not None:\n",
    "                fan_in, fan_out = \\\n",
    "                    nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "                bound = 1 / math.sqrt(fan_out)\n",
    "                nn.init.normal_(m.bias, -bound, bound)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모델 훈련과 검증\n",
    "---\n",
    "지금까지 다룬 부분을 조립해서 동작해볼 차례다.\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/76675506/190607812-e53f4a3f-eb5f-4e75-8814-9aa83f6c2324.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:137, LunaTrainingApp.main\n",
    "def main(self):\n",
    "    # ... 143 line\n",
    "    for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "\n",
    "        log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "            epoch_ndx,\n",
    "            self.cli_args.epochs,\n",
    "            len(train_dl),\n",
    "            len(val_dl),\n",
    "            self.cli_args.batch_size,\n",
    "            (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "        ))\n",
    "\n",
    "        trnMetrics_t = self.doTraining(epoch_ndx, train_dl)\n",
    "        self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "        valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "        self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "\n",
    "# ... 165 line\n",
    "def doTraining(self, epoch_ndx, train_dl):\n",
    "    self.model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE, # 빈 metric 배열 초기화\n",
    "        len(train_dl.dataset),\n",
    "        device=self.device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate( # 시간을 예측하며 배치 루프 설정\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        self.optimizer.zero_grad() # 남은 가중치 텐서 해제\n",
    "\n",
    "        loss_var = self.computeBatchLoss(\n",
    "            batch_ndx,\n",
    "            batch_tup,\n",
    "            train_dl.batch_size,\n",
    "            trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # # This is for adding the model graph to TensorBoard.\n",
    "        # if epoch_ndx == 1 and batch_ndx == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         model = LunaModel()\n",
    "        #         self.trn_writer.add_graph(model, batch_tup[0], verbose=True)\n",
    "        #         self.trn_writer.close()\n",
    "\n",
    "    self.totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "    return trnMetrics_g.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 훈련 루프가 이전과 다른 점은 다음과 같다.\n",
    "- `trnMetrics_g` 텐서가 훈련 중에 metric을 수집한다.(loggig)\n",
    "- `train_dl` 데이터 로더를 직접 순회하지 않는다.\n",
    "- 완료 시간 예측을 위한 `enumerateWithEstimate`를 사용한다.\n",
    "- 실제 손실 계산은 `computeBatchLoss`에서 이뤄진다.\n",
    "\n",
    "### computeBatchLoss 함수\n",
    "\n",
    "`computeBatchLoss`는 훈련 루프와 검증 루프 모두에서 호츨된다. 샘플 배치에 대한 손실을 계산하고, 부가적으로 모델이 만들어내는 출력에 대한 정보도 계산해서 기록한다. 이를 이용해서 클래스별로 계산이 얼마나 정확한지 알 수 있다.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(self.device, non_blocking=True)\n",
    "    label_g = label_t.to(self.device, non_blocking=True)\n",
    "\n",
    "    logits_g, probability_g = self.model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction='none') # 'none'으로 했을 때 샘플별 손실값을 얻는다.\n",
    "    loss_g = loss_func(\n",
    "        logits_g,\n",
    "        label_g[:,1], # 원핫 인코딩 클래스의 인덱스\n",
    "    )\n",
    "\n",
    "    # ... 238 line\n",
    "    return loss_g.mean() # 샘플별 손실값을 단일값으로 합친다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드는 손실값을 배치 단위로 구하지 않는다. 대신 클래스별로 손실값이 들어있는 텐서를 샘플마다 얻는다. 이를 통해 개별 손실값을 추적할 수 있고 원하는 방식(예를 들면 클래스별로)으로 합칠 수 있다.\n",
    "\n",
    "역전파 단계를 살펴보기 전에 추후 분석을 위해 샘플별 통계값을 기록하자. 이를 위해 파라미터로 받은 `metrics_g` 값을 이용한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "METRICS_LABEL_NDX=0\n",
    "METRICS_PRED_NDX=1\n",
    "METRICS_LOSS_NDX=2\n",
    "METRICS_SIZE = 3\n",
    "\n",
    "def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "        # ... 238 line\n",
    "        start_ndx = batch_ndx * batch_size\n",
    "        end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "        metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = \\ # 우리가 사용하는 metric들은 gradient를 유지할 필요가 없으므로 deatch\n",
    "            label_g[:,1].detach()\n",
    "        metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = \\ # detach()는 텐서를 복사하는 방법으로 gradient가 전파되지 않는 텐서가 생성된다.\n",
    "            probability_g[:,1].detach()\n",
    "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = \\\n",
    "            loss_g.detach()\n",
    "\n",
    "        return loss_g.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation loop\n",
    "\n",
    "validation loop은 training loop과 비슷하다. 단지 read-only인 점만 다르다. 즉, loss 값을 리턴하지 않고 가중치 또한 업데이트 되지 않는다.\n",
    "\n",
    "그 외에 다른 점은 동일하고 `with torch.no_grad()`로 인해 좀 더 빠르다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  training.py:137, LunaTrainingApp.main\n",
    "def main(self):\n",
    "    for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "        # ... 157 line\n",
    "        valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "        self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "\n",
    "def doValidation(self, epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        self.model.eval()   # 추론 모드\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            self.computeBatchLoss(\n",
    "                batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## metric 로깅하기\n",
    "\n",
    "epoch 마다 성능을 metirc으로 기록하는 것은 중요하다. 이를 통해 어떤 점이 문제인지, 어떻게 고칠 수 있을지 생각해볼 수 있기 때문이다. 추후에는 로그 데이터를 바탕으로 epoch의 사이즈를 조작해본다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:251, LunaTrainingApp.logMetrics\n",
    "def logMetrics(\n",
    "        self,\n",
    "        epoch_ndx, # 로깅하는 내역 나타내기\n",
    "        mode_str, # train인지 valid인지 구분\n",
    "        metrics_t, # trnMetrics_t 혹은 valMetrics_t\n",
    "        classificationThreshold=0.5,\n",
    "):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 마스크 구성하기\n",
    "\n",
    "결절 샘플 혹은 비결절 샘플에 대해서만 metric을 제한하는 마스크를 만들어보자"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# training.py:264, LunaTrainingApp.logMetrics\n",
    "        negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold # bool 값이 저장된 mask 생성\n",
    "        negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n",
    "\n",
    "        posLabel_mask = ~negLabel_mask\n",
    "        posPred_mask = ~negPred_mask\n",
    "\n",
    "\n",
    "        neg_count = int(negLabel_mask.sum())\n",
    "        pos_count = int(posLabel_mask.sum())\n",
    "\n",
    "        neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "        pos_correct = int((posLabel_mask & posPred_mask).sum())\n",
    "\n",
    "        metrics_dict = {}\n",
    "        metrics_dict['loss/all'] = \\\n",
    "            metrics_t[METRICS_LOSS_NDX].mean()\n",
    "        metrics_dict['loss/neg'] = \\\n",
    "            metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean() # 손실값을 클래스 별로도 저장해둔다. 이렇게 하면 특정 클래스에 대해 예측률이 낮을 때 개선하기 쉽다.\n",
    "        metrics_dict['loss/pos'] = \\\n",
    "            metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean()\n",
    "\n",
    "        metrics_dict['correct/all'] = (pos_correct + neg_correct) \\\n",
    "            / np.float32(metrics_t.shape[1]) * 100\n",
    "        metrics_dict['correct/neg'] = neg_correct / np.float32(neg_count) * 100\n",
    "        metrics_dict['correct/pos'] = pos_correct / np.float32(pos_count) * 100\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에서 계산한 결과를 `log.info`로 저장한다."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  log.info(\n",
    "            (\"E{} {:8} {loss/all:.4f} loss, \"\n",
    "                 + \"{correct/all:-5.1f}% correct, \"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\"E{} {:8} {loss/neg:.4f} loss, \"\n",
    "                 + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + '_neg',\n",
    "                neg_correct=neg_correct,\n",
    "                neg_count=neg_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\"E{} {:8} {loss/pos:.4f} loss, \"\n",
    "                 + \"{correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + '_pos',\n",
    "                pos_correct=pos_correct,\n",
    "                pos_count=pos_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 훈련 스크립트 실행"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}